---
layout:     post                    # 使用的布局（不需要改）
title:      Hadoop完全分布式搭建             # 标题 
subtitle:   操作步骤 #副标题
date:       2018-06-02              # 时间
author:     Yujie                      # 作者
header-img: img/post-bg-keybord.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - Hadoop
---

1. 一台机器是一个节点，可以多个节点在同一台机器，但是副本不能放在同一个节点
 2. node1机器作为namenode节点，node2和node3机器作为datanode节点，其中，node2节点作为bin/start-all.sh节点
 3. 每天机器都得安装Java的jdk，然后在/etc/profile下面配环境变量
 4. 然后每台机器都得解压hadoop压缩包，在Hadoop-env。sh里面配置Java——home
 5. 在其实一台机器上配置conf，比如在node1 上，首先，配置namenode，然后添加关于零时工作目录的配置，因为namenode的工作目录是以零时目录为参照的。这个零时工作目录叫做hadoop tmp dir
 6. Core-site 配置，hdfs-site配置，mapred-site配置
 7.  replication是配置副本数的，有几个datanode就可以写几。默认是3个副本。
 8. 设置免密登陆各台机器：首先正在本地产生公匙和私匙：ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa 
9. 然后把公匙加入到authorized—keys里面：cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
10. 这样本地机器就可以免密登陆自己。同理，把公匙给别的机器，然后追加到那台机器的authorized——keys里面，他也可以免密访问那台机器的。
11. 把本地这台机器的conf配置文件拷贝到其他机器的conf目录
12. 关闭防火墙systemctl stop firewalld.service
  格式化文件系统bin/hadoop namenode -format
13. 启动文件系统：bin/start-dfs.sh
14. 用jps查看Java进程
15. 通过实体电脑的/etc/hosts文件写入dns解析：node1:10.211.55.5这种
 16. 访问http://node1:50070

